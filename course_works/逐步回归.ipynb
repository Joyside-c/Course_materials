{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "from scipy.linalg import cholesky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成x\n",
    "mean=np.zeros(1000)\n",
    "cov =[]\n",
    "i=0\n",
    "while i < 1000:\n",
    "    cov.append(0.9**(np.arange(1000)+i))\n",
    "    i=i+1\n",
    "for i in range(1000):\n",
    "    cov[i][i]=1\n",
    "x= np.random.multivariate_normal(mean, cov, 100000)\n",
    "\n",
    "#生成用于生成真实y的β\n",
    "beta0=[]\n",
    "i=1\n",
    "while i <=1000:\n",
    "    if i%2 !=0:\n",
    "        beta0.append(1)\n",
    "    if i%2 ==0:\n",
    "        beta0.append(-1)\n",
    "    i=i+1\n",
    "    \n",
    "#生成y\n",
    "y=np.dot(x,beta0)+np.random.randn(100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 1000), (100000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  cholesky分解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy.linalg.cholesky() 返回的L是下三角阵\n",
    "# scipy.linalg.cholesky() 返回的L是上三角阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向前、回代函数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###mforwardsolve函数求解线性方程租Lx=b，其中L为下三角矩阵\n",
    "def mforwardsolve(L,b):\n",
    "    m=np.shape(L)[0]\n",
    "    n=np.shape(L)[1]\n",
    "    #0向量记录求解结果\n",
    "    x=np.zeros(m)\n",
    "    #循环每进行一次,求解一个x中的元素，看作矩阵L向量x向量b的维数减一\n",
    "    #故下述将矩阵L的第i列记为当前矩阵L第一列，将向量x向量b的第i个元素记为当前向量第一个元素\n",
    "    for i in range(m):\n",
    "        #求当前循环中x的第一个元素\n",
    "        x[i]=b[i]/L[i][i]\n",
    "        #降维后的b向量为原来位置上的元素减去当前矩阵L的第一列的乘积\n",
    "        if i<m-1:\n",
    "            b[i+1:]=b[i+1:]-x[i]*L[i+1:,i]\n",
    "    return x\n",
    "\n",
    "###mbacksolve函数求解线性方程租Lx=b，其中L为上三角矩阵\n",
    "#输入：上三角矩阵L，向量b\n",
    "#输出：线性方程组的解x\n",
    "def mbacksolve(L,b):\n",
    "    m=np.shape(L)[0]\n",
    "    n=np.shape(L)[1]\n",
    "    x=np.zeros(m)\n",
    "    #循环每进行一次,求解一个x中的元素，看作矩阵L向量x向量b的维数减一\n",
    "    #故下述将矩阵L的第i列记为当前矩阵L最后一列，将向量x向量b的第i个元素记为当前向量最后一个元素\n",
    "    for i in range(m-1,-1,-1):\n",
    "        x[i]=b[i]/L[i][i]\n",
    "        if i >0:\n",
    "            b[:i-1]=b[:i-1]-x[i]*L[:i-1,i]\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 逐步回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend.plotting'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d17e13003838>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_sequential_feature_selection\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplot_sfs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend.plotting'"
     ]
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改对应的BIC\n",
    "def steplm(x,y):\n",
    "    n=x.shape[0]\n",
    "    p=x.shape[1]\n",
    "    #加一列1\n",
    "    x=np.column_stack((x,np.ones(n)))\n",
    "    \n",
    "    xtx=mp.dot(x.T,x)\n",
    "    xty=np.dot(x.T,y)\n",
    "    yty=sum(y*y)\n",
    "    \n",
    "    L=numpy.linalg.cholesky(xtx)\n",
    "    tb=mforwardsolve(L, xty)\n",
    "    b=mbacksolve(L.T, tb)\n",
    "    \n",
    "    RSS=yty-sum(tb*tb)\n",
    "    AICF=n*log(RSS/n)+2*(p+1)\n",
    "    \n",
    "    A=np.range(p+1)\n",
    "    LA=L\n",
    "    MAIC=AICF\n",
    "    mAIC=AICF\n",
    "    MFLAG=\n",
    "    \n",
    "    ###啊啊啊写不完了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调包调包调包\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,k_features = 10,forward=True,floating=False, scoring='r2',cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.data import iris_data\n",
    "from mlxtend.plotting import plot_decision_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.linear_model import LinearRegression\n",
    "clf = LinearRegression()\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,k_features = 3,forward=True,floating=False, scoring='neg_mean_squared_error',cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'brier_score_loss',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '2', '3')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.06739797892954089"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs1.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SequentialFeatureSelector in module mlxtend.feature_selection.sequential_feature_selector:\n",
      "\n",
      "class SequentialFeatureSelector(mlxtend.utils.base_compostion._BaseXComposition, sklearn.base.MetaEstimatorMixin)\n",
      " |  SequentialFeatureSelector(estimator, k_features=1, forward=True, floating=False, verbose=0, scoring=None, cv=5, n_jobs=1, pre_dispatch='2*n_jobs', clone_estimator=True)\n",
      " |  \n",
      " |  Sequential Feature Selection for Classification and Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : scikit-learn classifier or regressor\n",
      " |  k_features : int or tuple or str (default: 1)\n",
      " |      Number of features to select,\n",
      " |      where k_features < the full feature set.\n",
      " |      New in 0.4.2: A tuple containing a min and max value can be provided,\n",
      " |          and the SFS will consider return any feature combination between\n",
      " |          min and max that scored highest in cross-validtion. For example,\n",
      " |          the tuple (1, 4) will return any combination from\n",
      " |          1 up to 4 features instead of a fixed number of features k.\n",
      " |      New in 0.8.0: A string argument \"best\" or \"parsimonious\".\n",
      " |          If \"best\" is provided, the feature selector will return the\n",
      " |          feature subset with the best cross-validation performance.\n",
      " |          If \"parsimonious\" is provided as an argument, the smallest\n",
      " |          feature subset that is within one standard error of the\n",
      " |          cross-validation performance will be selected.\n",
      " |  forward : bool (default: True)\n",
      " |      Forward selection if True,\n",
      " |      backward selection otherwise\n",
      " |  floating : bool (default: False)\n",
      " |      Adds a conditional exclusion/inclusion if True.\n",
      " |  verbose : int (default: 0), level of verbosity to use in logging.\n",
      " |      If 0, no output,\n",
      " |      if 1 number of features in current set, if 2 detailed logging i\n",
      " |      ncluding timestamp and cv scores at step.\n",
      " |  scoring : str, callable, or None (default: None)\n",
      " |      If None (default), uses 'accuracy' for sklearn classifiers\n",
      " |      and 'r2' for sklearn regressors.\n",
      " |      If str, uses a sklearn scoring metric string identifier, for example\n",
      " |      {accuracy, f1, precision, recall, roc_auc} for classifiers,\n",
      " |      {'mean_absolute_error', 'mean_squared_error'/'neg_mean_squared_error',\n",
      " |      'median_absolute_error', 'r2'} for regressors.\n",
      " |      If a callable object or function is provided, it has to be conform with\n",
      " |      sklearn's signature ``scorer(estimator, X, y)``; see\n",
      " |      http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html\n",
      " |      for more information.\n",
      " |  cv : int (default: 5)\n",
      " |      Integer or iterable yielding train, test splits. If cv is an integer\n",
      " |      and `estimator` is a classifier (or y consists of integer class\n",
      " |      labels) stratified k-fold. Otherwise regular k-fold cross-validation\n",
      " |      is performed. No cross-validation if cv is None, False, or 0.\n",
      " |  n_jobs : int (default: 1)\n",
      " |      The number of CPUs to use for evaluating different feature subsets\n",
      " |      in parallel. -1 means 'all CPUs'.\n",
      " |  pre_dispatch : int, or string (default: '2*n_jobs')\n",
      " |      Controls the number of jobs that get dispatched\n",
      " |      during parallel execution if `n_jobs > 1` or `n_jobs=-1`.\n",
      " |      Reducing this number can be useful to avoid an explosion of\n",
      " |      memory consumption when more jobs get dispatched than CPUs can process.\n",
      " |      This parameter can be:\n",
      " |      None, in which case all the jobs are immediately created and spawned.\n",
      " |          Use this for lightweight and fast-running jobs,\n",
      " |          to avoid delays due to on-demand spawning of the jobs\n",
      " |      An int, giving the exact number of total jobs that are spawned\n",
      " |      A string, giving an expression as a function\n",
      " |          of n_jobs, as in `2*n_jobs`\n",
      " |  clone_estimator : bool (default: True)\n",
      " |      Clones estimator if True; works with the original estimator instance\n",
      " |      if False. Set to False if the estimator doesn't\n",
      " |      implement scikit-learn's set_params and get_params methods.\n",
      " |      In addition, it is required to set cv=0, and n_jobs=1.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  k_feature_idx_ : array-like, shape = [n_predictions]\n",
      " |      Feature Indices of the selected feature subsets.\n",
      " |  k_feature_names_ : array-like, shape = [n_predictions]\n",
      " |      Feature names of the selected feature subsets. If pandas\n",
      " |      DataFrames are used in the `fit` method, the feature\n",
      " |      names correspond to the column names. Otherwise, the\n",
      " |      feature names are string representation of the feature\n",
      " |      array indices. New in v 0.13.0.\n",
      " |  k_score_ : float\n",
      " |      Cross validation average score of the selected subset.\n",
      " |  subsets_ : dict\n",
      " |      A dictionary of selected feature subsets during the\n",
      " |      sequential selection, where the dictionary keys are\n",
      " |      the lengths k of these feature subsets. The dictionary\n",
      " |      values are dictionaries themselves with the following\n",
      " |      keys: 'feature_idx' (tuple of indices of the feature subset)\n",
      " |            'feature_names' (tuple of feature names of the feat. subset)\n",
      " |            'cv_scores' (list individual cross-validation scores)\n",
      " |            'avg_score' (average cross-validation score)\n",
      " |      Note that if pandas\n",
      " |      DataFrames are used in the `fit` method, the 'feature_names'\n",
      " |      correspond to the column names. Otherwise, the\n",
      " |      feature names are string representation of the feature\n",
      " |      array indices. The 'feature_names' is new in v 0.13.0.\n",
      " |  \n",
      " |  Examples\n",
      " |  -----------\n",
      " |  For usage examples, please see\n",
      " |  http://rasbt.github.io/mlxtend/user_guide/feature_selection/SequentialFeatureSelector/\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SequentialFeatureSelector\n",
      " |      mlxtend.utils.base_compostion._BaseXComposition\n",
      " |      sklearn.utils.metaestimators._BaseComposition\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, k_features=1, forward=True, floating=False, verbose=0, scoring=None, cv=5, n_jobs=1, pre_dispatch='2*n_jobs', clone_estimator=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, custom_feature_names=None, groups=None, **fit_params)\n",
      " |      Perform feature selection and learn model from training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for X.\n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for y.\n",
      " |      custom_feature_names : None or tuple (default: tuple)\n",
      " |          Custom feature names for `self.k_feature_names` and\n",
      " |          `self.subsets_[i]['feature_names']`.\n",
      " |          (new in v 0.13.0)\n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Passed to the fit method of the cross-validator.\n",
      " |      fit_params : dict of string -> object, optional\n",
      " |          Parameters to pass to to the fit method of classifier.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  fit_transform(self, X, y, groups=None, **fit_params)\n",
      " |      Fit to training data then reduce X to its most important features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for X.\n",
      " |      y : array-like, shape = [n_samples]\n",
      " |          Target values.\n",
      " |          New in v 0.13.0: a pandas Series are now also accepted as\n",
      " |          argument for y.\n",
      " |      groups : array-like, with shape (n_samples,), optional\n",
      " |          Group labels for the samples used while splitting the dataset into\n",
      " |          train/test set. Passed to the fit method of the cross-validator.\n",
      " |      fit_params : dict of string -> object, optional\n",
      " |          Parameters to pass to to the fit method of classifier.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Reduced feature subset of X, shape={n_samples, k_features}\n",
      " |  \n",
      " |  get_metric_dict(self, confidence_interval=0.95)\n",
      " |      Return metric dictionary\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      confidence_interval : float (default: 0.95)\n",
      " |          A positive float between 0.0 and 1.0 to compute the confidence\n",
      " |          interval bounds of the CV score averages.\n",
      " |      \n",
      " |      Returns\n",
      " |      ----------\n",
      " |      Dictionary with items where each dictionary value is a list\n",
      " |      with the number of iterations (number of feature subsets) as\n",
      " |      its length. The dictionary keys corresponding to these lists\n",
      " |      are as follows:\n",
      " |          'feature_idx': tuple of the indices of the feature subset\n",
      " |          'cv_scores': list with individual CV scores\n",
      " |          'avg_score': of CV average scores\n",
      " |          'std_dev': standard deviation of the CV score average\n",
      " |          'std_err': standard error of the CV score average\n",
      " |          'ci_bound': confidence interval bound of the CV score average\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      Valid parameter keys can be listed with ``get_params()``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduce X to its most important features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |          New in v 0.13.0: pandas DataFrames are now also accepted as\n",
      " |          argument for X.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Reduced feature subset of X, shape={n_samples, k_features}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  named_estimators\n",
      " |      Returns\n",
      " |      -------\n",
      " |      List of named estimator tuples, like [('svc', SVC(...))]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
